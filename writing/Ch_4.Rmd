---
title: "Ch_4"
author: "Amy Fox"
date: "2/13/2020"
output: html_document
---

**Questions**
4.2 (right before 4.2.3) how do we actually use this for a biological question?

 - maybe the data is composed of 3 different types - expose mice and some belief that some mice have some level of different - see if there are truly different groups - can compare testing different group numbers - 
  - could also use if you lose the information for different grups 
  
4.3 (bootstrapping)  Then also is the bootstrap function the same as the replicate function? Do they do the same thing?

  - yes this is the same thing
  - non-parametric are really good to use (but you lose power because not assuming distribuiton)
  
  
Jack knife is similar to bootstrap - you remove 1 datapoint and then recalcualte
Then report the jack knife estimates - it shows how influlential each of the data points is 
calculate beta hat 
With all the birds the beta hat is ___ if I remove sinular birds, the range is 

this function exists in the bootstrap package



**Distributions**

- normal
- binomial - think of coin flip
- poisson - count data (can include rare observations)
- gamma - think waiting times - ex. time until a mouse dies, anything continuous that can't be negative

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 4.2 Finite Mixtures

Mixture model with 2 equal-sized components = flip a fair coin

```{r}
coinflips = (runif(10000) > 0.5)
table(coinflips)

oneFlip = function(fl, mean1 = 1, mean2 = 3, sd1 = 0.5, sd2 = 0.5) {
  if(fl) {
    rnorm(1, mean1, sd1)
  } else {
    rnorm(1, mean2, sd2)
  }
}

fairmix = vapply(coinflips, oneFlip, numeric(1))

library(ggplot2)
library(dplyr)

ggplot(tibble(value = fairmix), aes(x = value)) +
  geom_histogram(fill = "blue", binwidth = 0.1)


# or you can do it an easier way with vectorization
# try with 1 million coin flips

means = c(1, 3)
sds   = c(0.25, 0.25)
values = rnorm(length(coinflips),
          mean = ifelse(coinflips, means[1], means[2]),
          sd   = ifelse(coinflips, sds[1],   sds[2]))


fair = tibble(
  coinflips = (runif(1e6) > 0.5),
  values = rnorm(length(coinflips),
               mean = ifelse(coinflips, means[1], means[2]),
               sd   = ifelse(coinflips, sds[1],   sds[2])))
ggplot(fair, aes(x = values)) +
     geom_histogram(fill = "purple", bins = 500)


```

If we have 2 unfair coins with probabilities of head as p1 = 0.125 and p2 = 0.25 --> we then pick 1 coin and toss the coin twice to record the number of heads (K)

```{r}
probHead = c(0.125, 0.25)
for (pi in c(1/8, 1/4)) {
  whCoin = sample(2, 100, replace = TRUE, prob = c(pi, 1-pi))
  K = rbinom(length(whCoin), size = 2, prob = probHead[whCoin])
  print(table(K))
}
```

4.2.3 Zero inflated data

Note that this code will not run because they did not include the source code - will need to go to the source code for the chapter to download it

library(mosaicsExample)
library(mosaics)


bincts = print(binTFBS)
ggplot(bincts, aes(x = tagCount)) +
  geom_histogram(binwidth = 1, fill = "forestgreen")



4.2.4 More than 2 components
Weighing n = 7,000 nucleotides from mixtures of DNA 
```{r}
masses = c(A =  331, C =  307, G =  347, T =  322)
probs  = c(A = 0.12, C = 0.38, G = 0.36, T = 0.14)
N  = 7000
sd = 3
nuclt   = sample(length(probs), N, replace = TRUE, prob = probs)
quadwts = rnorm(length(nuclt),
                mean = masses[nuclt],
                sd   = sd)
ggplot(tibble(quadwts = quadwts), aes(x = quadwts)) +
  geom_histogram(bins = 100, fill = "purple")
```

# 4.3 Empirical Distributions and Nonparametric Bootstrap

Note that the ZeaMays data from the HistData package is the heights of 15 pairs of Zea Mays plants (self-hybridized vs crossed)
```{r}
library("HistData")
ZeaMays$diff
ggplot(ZeaMays, aes(x = diff, ymax = 1/15, ymin = 0)) +
  geom_linerange(size = 1, col = "forestgreen") + ylim(0, 0.1)

# Bootstrap the data to draw B = 1000 samples for size 15 from the 15 samples 

B = 1000
meds = replicate(B, {
  i = sample(15, 15, replace = TRUE)
  median(ZeaMays$diff[i])
})
ggplot(tibble(medians = meds), aes(x = medians)) +
  geom_histogram(bins = 30, fill = "purple")

# Compare the differences in bootstrapping with mean vs. median
library("bootstrap")
bootstrap(ZeaMays$diff, B, mean)
bootstrap(ZeaMays$diff, B, median)

# **Is this the same as what they were doing directly above with the replicate function?*

# If the sample is composed of n=3 different values, how many different bootstrap resamples are possible? Answer the same question with n = 15

# the way that you plug the numbers in is to do 2n-1 for the first value and n for the second

c(N3 = choose(5, 3), N15 = choose(29, 15))
```


# 4.4 Infinite Mixtures

Gamma-Poisson distribution
```{r}
lambda = rgamma(10000, shape = 10, rate = 3/2)
gp = rpois(length(lambda), lambda = lambda)
ggplot(tibble(x = gp), aes(x = x)) +
  geom_histogram(bins = 100, fill= "purple")


# Poisson variables with rates lambdas
lambdas = seq(100, 900, by = 100)
simdat = lapply(lambdas, function(l)
    tibble(y = rpois(n = 40, lambda=l), lambda = l)
  ) %>% bind_rows
library("ggbeeswarm")
ggplot(simdat, aes(x = lambda, y = y)) +
  geom_beeswarm(alpha = 0.6, color = "purple")
ggplot(simdat, aes(x = lambda, y = sqrt(y))) +
  geom_beeswarm(alpha = 0.6, color = "purple")
```



# Exercise 4.3

Mixture modeling examples for regression. The flexmix package (Grün, Scharl, and Leisch 2012) enables us to cluster and fit regressions to the data at the same time. The standard M-step FLXMRglm of flexmix is an interface to R’s generalized linear modeling facilities (the glm function). Load the package and an example dataset.


a) First, plot the data and try to guess how the points were generated.

yn = normal
yp = poisson
yb = binomial
```{r}
library("flexmix")
data("NPreg")

NPreg
library(ggplot2)
ggplot(data = NPreg, aes(x = x, y = yn, color = class)) +
  geom_point()

ggplot(data = NPreg, aes(x = x, y = yb, color = class)) +
  geom_point()

ggplot(data = NPreg, aes(x = x, y = yp, color = class)) +
  geom_point()
```

b) Fit a two component mixture model using the commands
```{r}
library(dplyr)
set.seed(10)
m1 = flexmix(yn ~ x + I(x^2), data = NPreg, k = 2) %>%
  print()

summary(m1)
```

c) Look at the estimated parameters of the mixture components and make a truth table that cross-classifies true classes versus cluster memberships. What does the summary of the object m1 show us?

```{r}
table(NPreg$class, clusters(m1))
```

Rows are the true clusters - the columns are the components that we added in
We can see that 5% are misclustered. 

d) Plot the data again, this time coloring each point according to its estimated class.

```{r}

library(gridExtra)
g1<- ggplot(data = NPreg, aes(x = x, y = yn, color = class)) +
  geom_point() +
  ggtitle("Actual labels")

g2 <- ggplot(data = NPreg, aes(x = x, y = yn, color = clusters(m1))) +
  geom_point() +
  ggtitle("Guessed labels")

grid.arrange(g1, g2)
```

Try the same thing with the Poisson
```{r}
m2 = flexmix(yp ~ x, data = NPreg, model = FLXMRglm(family = "poisson"), k = 2) %>%
  print()

table(NPreg$class, clusters(m2))


g3 <- ggplot(data = NPreg, aes(x = x, y = yp, color = class)) +
  geom_point() +
  ggtitle("Actual labels")

g4 <- ggplot(data = NPreg, aes(x = x, y = yp, color = clusters(m2))) +
  geom_point() +
  ggtitle("Guessed labels")

grid.arrange(g3, g4)
```

Try with binomial
```{r}
m3 <- initFlexmix(cbind(yb,1 - yb) ~ x, data = NPreg, k = 2,
                   model = FLXMRglm(family = "binomial"))

table(NPreg$class, clusters(m3))

g5 <- ggplot(data = NPreg, aes(x = x, y = yb, color = class)) +
  geom_point() +
  ggtitle("Actual labels")

g6 <- ggplot(data = NPreg, aes(x = x, y = yb, color = clusters(m3))) +
  geom_point() +
  ggtitle("Guessed labels")

grid.arrange(g5, g6)
```

