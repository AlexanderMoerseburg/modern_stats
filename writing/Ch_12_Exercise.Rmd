---
title: "Exercise Solution for Chapter 12"
author: "Amy Fox"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Exercise 12.2 from Modern Statistics for Modern Biologists

Use glmnet for a prediction of a continous variable, i.e., for regression. Use the prostate cancer data from Chapter 3 of (Hastie, Tibshirani, and Friedman 2008). The data are available in the CRAN package ElemStatLearn. Explore the effects of using ridge versus lasso penalty.


Here are the packages that need to be installed.
```{r message = FALSE}
# install.packages("glmnet")
library(dplyr)
library(glmnet)
library(ggplot2)
```

## Data for the exercise

The `ElemStatPackage` has been orphaned and isn't on CRAN anymore. However, it's up on
GitHub, so I grabbed the data file you'll need from there. You can download it 
yourself at: https://github.com/cran/ElemStatLearn/blob/master/data/prostate.RData

```{r}
load("../data/prostate.RData")

prostate %>% 
  head()
```

Here's a description of the data, from the archived help files: 

> "Data to examine the correlation between the level of prostate-specific
  antigen and a number of clinical measures in men who were about to 
  receive a radical prostatectomy."

Here's what the variables mean: 

- `lcavol`: log cancer volume
- `lweight`: log prostate weight
- `age`: in years
- `lbph`: log of the amount of benign prostatic hyperplasia
- `svi`: seminal vesicle invasion
- `lcp`: log of capsular penetration
- `gleason`: a numeric vector with the Gleason score
- `pgg45`: percent of Gleason score 4 or 5
- `lpsa`: response (the thing you are trying to predict), the 
level of prostate-specific antigen
- `train`: a logical vector, of whether the data was to be 
part of the training dataset (TRUE) or the testing one (FALSE)

So, you're trying to predict the values of `lpsa` based on the variables
`lcavol` through `pgg45`. 

We will first split the data into testing and training data.
```{r}
prostate_train <- prostate %>%
  filter(train == TRUE)

prostate_test <- prostate %>%
  filter(train == FALSE)

nrow(prostate_train)
nrow(prostate_test)

```

There are `r nrow(prostate_train)` samples in the training set and `r nrow(prostate_test)` samples in the testing set.

## Fit generaltized linear model (glmnet) with Lasso and Ridge penalties

Here, we use a matrix of all of the predictors (`x`) to try to predict the `lpsa` column (`y`).

Based on the glmnet package, when alpha = 1 the lasso penalty is used, if alpha = 0, then ridge penalty is used. A great resource for the glmnet package can be found here: <https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html>

```{r}
# Lasso 
lasso_glmnet <- glmnet(x = prostate_train %>% dplyr::select(lcavol:pgg45) %>% as.matrix(), 
                    y = prostate_train %>% pull(lpsa), 
                    family = "gaussian", alpha = 1)

plot(lasso_glment, label = TRUE)
title("Lasso Penalty", line = -2.5)

# Ridge
ridge_glmnet <- glmnet(x = prostate_train %>% dplyr::select(lcavol:pgg45) %>% as.matrix(), 
                    y = prostate_train %>% pull(lpsa), 
                    family = "gaussian", alpha = 0)

plot(ridge_glmnet, label = TRUE)
title("Ridge Penalty", line = -1.5)
```

In the plots show the coefficients as L1- norm increases. The top axis shows the number of nonzero coefficients correspoding to the lamba at the current L1 norm. From these plots we can see that predictors 1, 2, and 5 are good predictors for the lpsa response.


## Cross Validation

We then want to perform cross-validation on the dataset. We use the cv.glmnet function to do this. 

```{r}
set.seed(2)

# Lasso
cvglmnet_lasso <- cv.glmnet(x = prostate_train %>% dplyr::select(lcavol:pgg45) %>% as.matrix(), 
                    y = prostate_train %>% pull(lpsa), 
                    family = "gaussian", alpha = 0)
cvglmnet_lasso

plot(cvglmnet_lasso)
title("Lasso Cross Validation", line = -1.5)

# Ridge
cvglmnet_ridge <- cv.glmnet(x = prostate_train %>% dplyr::select(lcavol:pgg45) %>% as.matrix(), 
                    y = prostate_train %>% pull(lpsa), 
                    family = "gaussian", alpha = 1)
cvglmnet_ridge

plot(cvglmnet_ridge)
title("Ridge Cross Validation", line = -1.5)
```
Min: minimum lambda 
1se: within 1 standard error of the minimum lambda - this is the value that the model suggests that we use (2nd dotted line on the plot).

The `1se Measure`  is similar to the mean squared error. If the measure is small, then the model is better. When comparing the `Measure` of the `1se` between the two penalties, we can see that the Ridge Penalty has a smaller 1se Measure, showing that it performs better. 

The Nonzero column describes the nonzero coefficients, or the number of predictors that are important in the particular model. There were a total of 8 predictors as the input. The Lasso penalty shows that all 8 predicotrs are important in building the model, but the Ridge penalty only uses 5 predictors.

## Lasso Prediction 

As we used the training data to build the model, we can then test the generalized linear model with the lasso penalty on the testing data.

We start by using the `predict` function to use the model to predict the lpsa on the testing data. We can then see the correlation between the predicted values and actual values.
```{r}
s0 <- cvglmnet_lasso$lambda.1se 

lasso_predict <- predict(cvglmnet_lasso, newx = prostate_test%>% dplyr::select(lcavol:pgg45) %>% as.matrix(), s = s0)

# create a data frame of the actual lpsa values and the predicted lpsa values
actual_lasso_predict_df <- data.frame(prediction = as.vector(lasso_predict), actual = prostate_test$lpsa)

```

We can then see how correlated the prediction and real data are.
```{r}
# look at the correlation of the prediction and real data
cor(actual_lasso_predict_df)
```
They are 72% correlated.

We can then fit a linear line to the prediction and actual data and look at the r^2 value
```{r}
lm(actual_lasso_predict_df) %>%
  summary()
```

The adjusted r^2 value = 0.513

Finally, we can plot the actual vs. predicted values on a scatter plot. If the actual and predicted values matched up exactly, they would sit on the y = x line.
```{r}
ggplot(actual_lasso_predict_df, aes(x = actual, y = prediction)) +
  geom_point(color = "#00B0F6", size = 2) +
  geom_abline(slope=1, intercept=0)+
  ggtitle("Lasso Prediction") +
  theme_light()
```


## Ridge Prediction 

We can then perform the same functions using the  generalized linear model with the ridge penalty to test on the testing data.

```{r}
s0 <- cvglmnet_ridge$lambda.1se 

ridge_predict <- predict(cvglmnet_ridge, newx = prostate_test%>% dplyr::select(lcavol:pgg45) %>% as.matrix(), s = s0)

prostate_test$lpsa

actual_ridge_predict_df <- data.frame(prediction = as.vector(ridge_predict), actual = prostate_test$lpsa) 
```

We can then see how correlated the prediction and real data are.
```{r}
cor(actual_ridge_predict_df)
```
The ridge prediction and acutal values are 77% correlated.

We can then fit a linear line to the prediction and actual data and look at the r^2 value
```{r}
lm(actual_ridge_predict_df) %>%
  summary()
```
The adjusted r^2 value = 0.589

Finally, we can plot the actual vs. predicted values on a scatter plot. If the actual and predicted values matched up exactly, they would sit on the y = x line.
```{r}
ggplot(actual_ridge_predict_df, aes(x = actual, y = prediction)) +
  geom_point(color = "#FF62BC", size = 2) +
  geom_abline(slope=1, intercept=0) +
  ggtitle("Ridge Prediction") +
  theme_light()
```

## Conclusion

Comparing the Lasso and Ridge Penalty, based on the cross-validation, the ridge penalty had a smaller 1se Measure, showing that it performs better. When looking at the actual predictions on the testing data, the ridge penalty had a higher correlation between the predicted and acutal values (77%) compared to the lasso penatly correlation (72%). Further, when fitting a linear model to the actual and predicted values, the r^2 values were highter for the ridge penalty (0.589) versus the lasso penalty (0.513). In conclusion, the ridge penalty performed better on this particular data set.